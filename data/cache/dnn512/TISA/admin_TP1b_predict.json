{
    "alexandra.larsonneur@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5 :\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "alexandra.larsonneur@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5 :\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-03 15:17:37",
        "atype": "bkcode"
    },
    "alexis.akujuobi-asoluka@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X)+b) #done\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0][i] <= 0.5: #done\n            Y_prediction[0] [i] = 0 #done\n        else :\n            Y_prediction[0] [i] = 1 #done\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "alexis.akujuobi-asoluka@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X)+b) #done\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0][i] <= 0.5: #done\n            Y_prediction[0] [i] = 0 #done\n        else :\n            Y_prediction[0] [i] = 1 #done\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-03 19:42:40",
        "atype": "bkcode"
    },
    "ali.m-sahi@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X+b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "ali.m-sahi@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X+b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-04 13:44:00",
        "atype": "bkcode"
    },
    "angel.jouen@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5:\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "angel.jouen@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5:\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-04 16:01:18"
    },
    "antoine.rochette@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: \n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "antoine.rochette@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: \n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-03 15:36:49",
        "atype": "bkcode"
    },
    "arij.salablab@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(np.transpose(w), X) + b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5 : # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "arij.salablab@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(np.transpose(w), X) + b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5 : # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-03 21:40:42",
        "atype": "bkcode"
    },
    "armand.loisil@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X)+b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5 : # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "armand.loisil@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X)+b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5 : # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-03 15:17:36",
        "atype": "bkcode"
    },
    "axel.streiff@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X) + b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...   #  DETECTED NON CAT \n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...  # DETECTED CAT \n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "axel.streiff@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X) + b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...   #  DETECTED NON CAT \n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...  # DETECTED CAT \n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-04 15:48:50"
    },
    "badis.perdrix@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "badis.perdrix@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-04 17:56:19",
        "atype": "bkcode"
    },
    "baptiste.rousselet@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = 1 / (1 + np.exp(-(np.dot(w.T, X) + b))) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= -1: # Fix this line...\n            Y_prediction[0, i] = -1 # Fix this line...\n        else :\n            Y_prediction[0, i] = -1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "baptiste.rousselet@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = 1 / (1 + np.exp(-(np.dot(w.T, X) + b))) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= -1: # Fix this line...\n            Y_prediction[0, i] = -1 # Fix this line...\n        else :\n            Y_prediction[0, i] = -1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 0.0,
        "update_time": "2023-10-04 11:07:34",
        "atype": "bkcode"
    },
    "colin.duchanoy@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if(A[0][i] <= 0.5):\n            Y_prediction[0][i] = 0\n        else:\n            Y_prediction[0][i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "colin.duchanoy@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if(A[0][i] <= 0.5):\n            Y_prediction[0][i] = 0\n        else:\n            Y_prediction[0][i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-03 15:22:43"
    },
    "dorian.rondeau@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X+b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5:\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "dorian.rondeau@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X+b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5:\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-04 10:46:29"
    },
    "evan.garcia@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "evan.garcia@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-04 10:57:47"
    },
    "gaetan.chiesura@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A =  sigmoid(w.T@X+b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "gaetan.chiesura@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A =  sigmoid(w.T@X+b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-04 16:09:56"
    },
    "geoffrey.vaillant@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0, i] <= 0.5:\n            Y_prediction[0, i] = 0\n        else:\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "geoffrey.vaillant@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0, i] <= 0.5:\n            Y_prediction[0, i] = 0\n        else:\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-04 13:35:15",
        "atype": "bkcode"
    },
    "john.doe@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.transpose(w)@X+b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "john.doe@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.transpose(w)@X+b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-04 10:46:24",
        "atype": "bkcode"
    },
    "julian.lavarelo@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X + b) # Fix this line...\n    ### END CODE HERE ###\n    \n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "julian.lavarelo@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X + b) # Fix this line...\n    ### END CODE HERE ###\n    \n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-04 10:47:12"
    },
    "lea.dupin@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T @ X + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5:\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "lea.dupin@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T @ X + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5:\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-04 10:44:20"
    },
    "luc.fourty@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b)      # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "luc.fourty@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b)      # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-04 13:41:21"
    },
    "luc.sauleau@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "luc.sauleau@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X) + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-03 15:59:54"
    },
    "mathieu.klingler@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X)+b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "mathieu.klingler@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T,X)+b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-03 15:23:02"
    },
    "matteo.crosnier-de-bellaistre@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.transpose(w)@X+b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "matteo.crosnier-de-bellaistre@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.transpose(w)@X+b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-04 08:43:50"
    },
    "mikael.kealbert@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "mikael.kealbert@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X + b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-04 10:53:12"
    },
    "nathan.heckmann@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    z = w.T @ X + b\n    A = sigmoid(z)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5:\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "nathan.heckmann@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    z = w.T @ X + b\n    A = sigmoid(z)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5:\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-04 14:58:53",
        "atype": "bkcode"
    },
    "nils.joanne@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X+b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "nils.joanne@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X+b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-03 15:09:38",
        "atype": "bkcode"
    },
    "riccardo.cecchetto@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X + b)# Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "riccardo.cecchetto@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X + b)# Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-03 15:23:08",
        "atype": "bkcode"
    },
    "romain.miaux@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    z = w.T @ X + b\n    A = sigmoid(z)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5:\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "romain.miaux@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    z = w.T @ X + b\n    A = sigmoid(z)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5:\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "atype": "bkcode",
        "update_time": "2023-10-04 16:05:46"
    },
    "solution": {
        "update_time": "2023-10-10 23:02:33",
        "visible": true,
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1, m))\n    print(\"X.shape=\", X.shape, \"m=\", m, \"w.shape=\", w.shape)\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X+b)\n    print(\"A.shape=\", A.shape)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0,i] to actual predictions p[0,i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5 :\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\nprint(\"predictions = \" + str(predict(w, b, X)))\n\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n\n",
        "note_upd": "2023-10-11 08:24:10",
        "explanation": "",
        "evaluation": "def student_evaluation_function():\n  score = bulkhours.is_equal(data_test=student.pred, max_score=5.0, data_ref=teacher.pred, min_score=0)\n\n  return score\n",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1, m))\n    print(\"X.shape=\", X.shape, \"m=\", m, \"w.shape=\", w.shape)\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(w.T@X+b)\n    print(\"A.shape=\", A.shape)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0,i] to actual predictions p[0,i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5 :\n            Y_prediction[0, i] = 0\n        else :\n            Y_prediction[0, i] = 1\n\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\nprint(\"predictions = \" + str(predict(w, b, X)))\n\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n\n",
        "user": "solution",
        "note": 5.0,
        "atype": "bkcode",
        "hint": ""
    },
    "sualp.komurcuoglu@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "sualp.komurcuoglu@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-04 14:00:24",
        "atype": "bkcode"
    },
    "thibaud.bonnet@ipsa.fr": {
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else:\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note_upd": "2023-10-11 08:24:10",
        "user": "thibaud.bonnet@ipsa.fr",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    A = sigmoid(np.dot(w.T, X) + b) # Fix this line...\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else:\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "note": 5.0,
        "update_time": "2023-10-04 12:06:30",
        "atype": "bkcode"
    },
    "yann-loic-atasse.atakoui@ipsa.fr": {
        "note_upd": "2023-10-11 08:24:10",
        "note": 5.0,
        "answer": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    #A = np.array([[]]) # Fix this line...\n    A = sigmoid(w.T@X+b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "main_execution": "def predict(w, b, X):\n    '''\n    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n\n    Arguments:\n    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n    b -- bias, a scalar\n    X -- data of size (num_px * num_px * 3, number of examples)\n\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n    '''\n\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n\n    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n    ### START CODE HERE ###\n    #A = np.array([[]]) # Fix this line...\n    A = sigmoid(w.T@X+b)\n    ### END CODE HERE ###\n\n    for i in range(A.shape[1]):\n\n        # Convert probabilities A[0, i] to actual predictions p[0, i]\n        ### START CODE HERE ###\n        if A[0,i] <= 0.5: # Fix this line...\n            Y_prediction[0, i] = 0 # Fix this line...\n        else :\n            Y_prediction[0, i] = 1 # Fix this line...\n        ### END CODE HERE ###\n\n    assert(Y_prediction.shape == (1, m))\n\n    return Y_prediction\n\nw = np.array([[0.1124579],[0.23106775]])\nb = -0.3\nX = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\npred = predict(w, b, X)\nprint(f\"predictions = {pred}\")\nprint(pred.shape)\nprint(\"prediction\", pred[0, 1])\nprint(classes[int(pred[0, 1])])\n",
        "user": "yann-loic-atasse.atakoui@ipsa.fr ",
        "atype": "bkcode",
        "update_time": "2023-10-04 14:15:47"
    }
}